{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYbFJTRBrUb8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to RAVDESS dataset\n",
        "dataset_path = '/content/drive/MyDrive/Audio_Song_Actors_01-24'\n",
        "\n",
        "# Define emotion mapping based on RAVDESS labels\n",
        "emotion_mapping = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(audio_path, max_length=200):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    mfcc_transform = torchaudio.transforms.MFCC(\n",
        "        sample_rate=sample_rate,\n",
        "        n_mfcc=13,\n",
        "        melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 23, \"center\": False}\n",
        "    )\n",
        "    mfcc_features = mfcc_transform(waveform)\n",
        "\n",
        "    # Pad or truncate to max_length\n",
        "    mfcc_features = mfcc_features[:, :, :max_length] if mfcc_features.shape[2] >= max_length else torch.nn.functional.pad(mfcc_features, (0, max_length - mfcc_features.shape[2]))\n",
        "\n",
        "    return mfcc_features.mean(dim=0).flatten().numpy()  # Average across channels and flatten\n",
        "\n",
        "# Load dataset and prepare features and labels\n",
        "features_list = []\n",
        "labels = []\n",
        "\n",
        "for root, _, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            emotion_code = file.split(\"-\")[2]  # Extract emotion code\n",
        "            emotion_label = emotion_mapping[emotion_code]\n",
        "\n",
        "            # Extract MFCC features\n",
        "            mfcc_features = extract_features(file_path)\n",
        "            features_list.append(mfcc_features)\n",
        "            labels.append(emotion_code)  # Using code for numeric encoding\n",
        "\n",
        "# Pad features to have the same length\n",
        "max_length = max(feature.shape[0] for feature in features_list) // 13\n",
        "padded_features = [\n",
        "    np.pad(feature, (0, max_length * 13 - len(feature)), mode='constant')\n",
        "    if len(feature) < max_length * 13 else feature\n",
        "    for feature in features_list\n",
        "]\n",
        "\n",
        "# Convert to numpy arrays and encode labels as integers\n",
        "features = np.array(padded_features, dtype=np.float32)\n",
        "labels = np.array([int(label) - 1 for label in labels])  # Make labels 0-indexed\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define a simple neural network for mood detection\n",
        "class MoodClassifier(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MoodClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)  # Increased neurons\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, len(emotion_mapping))  # Output layer for 8 emotions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)  # Added dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "input_size = max_length * 13\n",
        "model = MoodClassifier(input_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Added learning rate scheduler\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 30  # Increased epochs\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    scheduler.step()  # Step the scheduler\n",
        "\n",
        "# Test the model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "# Function to detect mood of a song\n",
        "def detect_mood(audio_path):\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    model.eval()\n",
        "    features = extract_features(audio_path, max_length=max_length)\n",
        "    features = torch.tensor(features, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "    with torch.no_grad():\n",
        "        output = model(features)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        emotion = list(emotion_mapping.values())[predicted.item()]\n",
        "    print(f\"Detected mood: {emotion}\")\n",
        "\n",
        "# Example usage\n",
        "detect_mood('/content/drive/MyDrive/audio/smallville-music_radiohead-creep.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFMqvu78rfHF",
        "outputId": "ea711d82-cdeb-4e54-85cd-3479d7263faf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 4.0089, Validation Loss: 2.1967\n",
            "Epoch [2/30], Loss: 1.9513, Validation Loss: 1.8679\n",
            "Epoch [3/30], Loss: 1.8904, Validation Loss: 1.8707\n",
            "Epoch [4/30], Loss: 1.8998, Validation Loss: 1.8578\n",
            "Epoch [5/30], Loss: 1.8550, Validation Loss: 1.7765\n",
            "Epoch [6/30], Loss: 1.8528, Validation Loss: 1.7868\n",
            "Epoch [7/30], Loss: 1.8471, Validation Loss: 1.7946\n",
            "Epoch [8/30], Loss: 1.8398, Validation Loss: 1.7977\n",
            "Epoch [9/30], Loss: 1.8188, Validation Loss: 1.8272\n",
            "Epoch [10/30], Loss: 1.8224, Validation Loss: 1.7894\n",
            "Epoch [11/30], Loss: 1.8029, Validation Loss: 1.7827\n",
            "Epoch [12/30], Loss: 1.8118, Validation Loss: 1.7988\n",
            "Epoch [13/30], Loss: 1.8307, Validation Loss: 1.7805\n",
            "Epoch [14/30], Loss: 1.8073, Validation Loss: 1.8341\n",
            "Epoch [15/30], Loss: 1.7852, Validation Loss: 1.7901\n",
            "Epoch [16/30], Loss: 1.7795, Validation Loss: 1.7887\n",
            "Epoch [17/30], Loss: 1.7715, Validation Loss: 1.7845\n",
            "Epoch [18/30], Loss: 1.7927, Validation Loss: 1.7662\n",
            "Epoch [19/30], Loss: 1.7871, Validation Loss: 1.7832\n",
            "Epoch [20/30], Loss: 1.7758, Validation Loss: 1.7847\n",
            "Epoch [21/30], Loss: 1.7686, Validation Loss: 1.7774\n",
            "Epoch [22/30], Loss: 1.7814, Validation Loss: 1.7840\n",
            "Epoch [23/30], Loss: 1.7801, Validation Loss: 1.7812\n",
            "Epoch [24/30], Loss: 1.7679, Validation Loss: 1.7765\n",
            "Epoch [25/30], Loss: 1.7579, Validation Loss: 1.7793\n",
            "Epoch [26/30], Loss: 1.7714, Validation Loss: 1.7763\n",
            "Epoch [27/30], Loss: 1.7719, Validation Loss: 1.7731\n",
            "Epoch [28/30], Loss: 1.7917, Validation Loss: 1.7753\n",
            "Epoch [29/30], Loss: 1.7579, Validation Loss: 1.7744\n",
            "Epoch [30/30], Loss: 1.7761, Validation Loss: 1.7735\n",
            "Test Accuracy: 20.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-28db6fc47170>:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n",
            "<ipython-input-5-28db6fc47170>:154: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected mood: angry\n"
          ]
        }
      ]
    }
  ]
}